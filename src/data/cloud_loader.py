"""
–ú–æ–¥—É–ª—å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞ –±–µ–∑ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –ü—Ä—è–º–æ–µ —á—Ç–µ–Ω–∏–µ Parquet —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ HTTP/HTTPS (polars)
- –†–∞–±–æ—Ç—É —Å –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ API
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
"""

import os
import re
from typing import Optional, List, Dict
from pathlib import Path
import polars as pl
import requests
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
from src.utils.yandex_cloud import (
    YANDEX_DISK_CLIENT_ID,
    YANDEX_DISK_CLIENT_SECRET,
    YANDEX_DISK_REDIRECT_URI
)


class YandexDiskLoader:
    """
    –ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö —Å –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞:
    1. –ü—É–±–ª–∏—á–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (–µ—Å–ª–∏ –ø–∞–ø–∫–∞ –ø—É–±–ª–∏—á–Ω–∞—è)
    2. API —Å —Ç–æ–∫–µ–Ω–æ–º (–¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –ø–∞–ø–æ–∫)
    """
    
    def __init__(
        self,
        public_link: Optional[str] = None,
        api_token: Optional[str] = None,
        cache_dir: Optional[str] = None,
        base_path: Optional[str] = None,
        prefer_cache: bool = False
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥—Ä—É–∑—á–∏–∫–∞.
        
        :param public_link: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–∞–ø–∫—É –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞
                           –ü—Ä–∏–º–µ—Ä: "https://disk.yandex.ru/d/H0ZTzS55GSz1Wg"
        :param api_token: –¢–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        :param cache_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å dataset (–¥–ª—è API —Å —Ç–æ–∫–µ–Ω–æ–º)
                         –ü—Ä–∏–º–µ—Ä: "/–ó–∞–≥—Ä—É–∑–∫–∏/Dataset_case_1" –∏–ª–∏ "–ó–∞–≥—Ä—É–∑–∫–∏/Dataset_case_1"
                         –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ—Ä–µ–Ω—å –¥–∏—Å–∫–∞
        :param prefer_cache: –ï—Å–ª–∏ True, —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫
                           –∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑ –æ–±–ª–∞–∫–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –≤ –∫—ç—à–µ
        """
        self.public_link = public_link
        self.api_token = api_token or os.getenv("YANDEX_DISK_TOKEN")
        self.cache_dir = cache_dir or ".cache"
        self.prefer_cache = prefer_cache
        
        # –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ dataset (–Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º: —É–±–∏—Ä–∞–µ–º disk:, –¥–æ–±–∞–≤–ª—è–µ–º / –≤ –Ω–∞—á–∞–ª–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
        if base_path:
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å disk: –µ—Å–ª–∏ –µ—Å—Ç—å
            base_path = base_path.replace("disk:", "").strip()
            # –£–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π / –µ—Å–ª–∏ –µ—Å—Ç—å (API —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ —Å –Ω–∏–º, –∏ –±–µ–∑)
            if base_path.startswith("/"):
                base_path = base_path[1:]
            self.base_path = base_path
        else:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è
            env_base_path = os.getenv("YANDEX_DISK_BASE_PATH")
            if env_base_path:
                env_base_path = env_base_path.replace("disk:", "").strip()
                if env_base_path.startswith("/"):
                    env_base_path = env_base_path[1:]
                self.base_path = env_base_path
            else:
                self.base_path = None
        
        # –ë–∞–∑–æ–≤—ã–π URL –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
        if public_link:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –ø–∞–ø–∫–∏ –∏–∑ —Å—Å—ã–ª–∫–∏
            match = re.search(r'/d/([a-zA-Z0-9_-]+)', public_link)
            if match:
                self.folder_id = match.group(1)
                self.base_url = f"https://disk.yandex.ru/d/{self.folder_id}"
            else:
                raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –ø—É–±–ª–∏—á–Ω–æ–π —Å—Å—ã–ª–∫–∏")
        
        # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω –Ω–µ —É–∫–∞–∑–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ OAuth
        if not self.api_token:
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OAuth
            # –î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –Ω—É–∂–Ω–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            # –ü–æ–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø, –Ω–æ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
            print("‚ö† –í–ù–ò–ú–ê–ù–ò–ï: API —Ç–æ–∫–µ–Ω –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞ –Ω–µ —É–∫–∞–∑–∞–Ω.")
            print("   –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã")
            print("   –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –≤–º–µ—Å—Ç–æ —Ñ–∞–π–ª–æ–≤ (–∫–∞–ø—á–∞, –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞).")
            print("   OAuth credentials –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã, –Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
            print("   –î–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–∞–±–æ—Ç—ã —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –≤—Ä—É—á–Ω—É—é –Ω–∞ https://oauth.yandex.ru/")
            print("   –∏ –¥–æ–±–∞–≤–∏—Ç—å –µ–≥–æ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è YANDEX_DISK_TOKEN.")
    
    def _get_download_link(self, file_path: str) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞.
        
        :param file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø–∞–ø–∫–∏
        :return: –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        """
        if self.api_token:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–∏
            return self._get_api_download_link(file_path)
        else:
            # –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            import urllib.parse
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫: –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /download —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            # –ü—É—Ç—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä
            if "/" in file_path:
                # –î–ª—è –ø—É—Ç–µ–π —Å / –∫–æ–¥–∏—Ä—É–µ–º –≤–µ—Å—å –ø—É—Ç—å —Ü–µ–ª–∏–∫–æ–º
                encoded_path = urllib.parse.quote(file_path, safe='')
            else:
                encoded_path = urllib.parse.quote(file_path, safe='')
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫
            # –í–∞—Ä–∏–∞–Ω—Ç 1: —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç (–º–æ–∂–µ—Ç —Ç—Ä–µ–±–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é)
            download_url = f"https://disk.yandex.ru/d/{self.folder_id}/download?path={encoded_path}"
            
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç: –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É
            # –ù–æ —ç—Ç–æ –Ω–µ –≤—Å–µ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –ø–æ–¥–ø–∞–ø–æ–∫
            
            return download_url
    
    def _get_api_download_link(self, file_path: str) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É —á–µ—Ä–µ–∑ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ API.
        
        :param file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏ –∏–ª–∏ –∫–æ—Ä–Ω—è)
        :return: –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å —Å —É—á–µ—Ç–æ–º –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏
        full_path = self._get_full_path(file_path)
        
        url = "https://cloud-api.yandex.net/v1/disk/resources/download"
        headers = {"Authorization": f"OAuth {self.api_token}"}
        params = {"path": full_path}
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        
        return response.json()["href"]
    
    def _get_full_path(self, relative_path: str) -> str:
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —É—á–µ—Ç–æ–º –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏.
        
        :param relative_path: –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "marketplace/events/01082.pq")
        :return: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, "/–ó–∞–≥—Ä—É–∑–∫–∏/Dataset_case_1/marketplace/events/01082.pq")
        """
        if self.base_path:
            # –£–±–∏—Ä–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–π / –∏–∑ relative_path –µ—Å–ª–∏ –µ—Å—Ç—å
            if relative_path.startswith("/"):
                relative_path = relative_path[1:]
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
            full_path = f"/{self.base_path}/{relative_path}"
            # –£–±–∏—Ä–∞–µ–º –¥–≤–æ–π–Ω—ã–µ —Å–ª–µ—à–∏
            full_path = full_path.replace("//", "/")
            return full_path
        else:
            # –ï—Å–ª–∏ –±–∞–∑–æ–≤—ã–π –ø—É—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º relative_path –∫–∞–∫ –µ—Å—Ç—å
            if not relative_path.startswith("/"):
                relative_path = f"/{relative_path}"
            return relative_path
    
    def list_files(self, folder_path: str = "") -> List[Dict[str, str]]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ.
        
        :param folder_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è)
        :return: –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if self.api_token:
            return self._list_files_api(folder_path)
        else:
            # –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –±–µ–∑ API —Ç–æ–∫–µ–Ω–∞ –º—ã –Ω–µ –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ - –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å file_list –ø–∞—Ä–∞–º–µ—Ç—Ä
            return []
    
    def _list_files_api(self, folder_path: str) -> List[Dict[str, str]]:
        """
        –°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API.
        
        :param folder_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏)
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å —Å —É—á–µ—Ç–æ–º –±–∞–∑–æ–≤–æ–≥–æ –ø—É—Ç–∏
        full_path = self._get_full_path(folder_path)
        
        url = "https://cloud-api.yandex.net/v1/disk/resources"
        headers = {"Authorization": f"OAuth {self.api_token}"}
        params = {"path": full_path, "limit": 1000}
        
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        
        items = response.json().get("_embedded", {}).get("items", [])
        return [
            {
                "name": item["name"],
                "path": item["path"],
                "type": item["type"],
                "size": item.get("size", 0)
            }
            for item in items
        ]
    
    def read_parquet_from_url(
        self,
        file_path: str,
        use_cache: bool = True,
        normalize: bool = True
    ) -> pl.DataFrame:
        """
        –ß–∏—Ç–∞–µ—Ç Parquet —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞.
        
        –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–æ—Ä–º–∞—Ç:
        https://disk.yandex.ru/d/{folder_id}/download?path={encoded_path}
        
        :param file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø–∞–ø–∫–∏
        :param use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –∫—ç—à
        :param normalize: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ (–ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É)
        :return: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
        """
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        download_url = self._get_download_link(file_path)
        
        # –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç range requests, –ø–æ—ç—Ç–æ–º—É –≤—Å–µ–≥–¥–∞ —Å–∫–∞—á–∏–≤–∞–µ–º —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É —Ñ–∞–π–ª–∞
        try:
            df = self._read_with_temp_file(download_url, file_path, use_cache)
        except Exception as e:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª {file_path}: {e}")
            return pl.DataFrame()
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if normalize:
            from src.data.data_parser import normalize_dataframe, detect_data_structure
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–µ–Ω –∏–∑ –ø—É—Ç–∏
            domain = "unknown"
            if "marketplace" in file_path:
                domain = "marketplace"
            elif "payments" in file_path:
                domain = "payments"
            elif "retail" in file_path:
                domain = "retail"
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                structure = detect_data_structure(df)
                domain = structure.get("type", "unknown")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            if domain != "unknown":
                df = normalize_dataframe(df, domain, file_path)
        
        return df
    
    def _read_with_temp_file(
        self,
        download_url: str,
        file_path: str,
        use_cache: bool
    ) -> pl.DataFrame:
        """
        –ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
        
        –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑ –∫—ç—à–∞.
        
        –õ–û–ì–ò–ö–ê –†–ê–ë–û–¢–´ –° –î–ê–¢–ê–ú–ò:
        - –§–∞–π–ª—ã –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è —Ç–∏–ø–∞ 01082.pq, 01083.pq - —ç—Ç–æ –Ω–æ–º–µ—Ä–∞ –¥–Ω–µ–π (day numbers)
        - –ö–∞–∂–¥—ã–π —Ñ–∞–π–ª –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π
        - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–∞–º –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ü–û–°–õ–ï –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ –∫–æ–ª–æ–Ω–∫–µ timestamp
        - –ü–∞—Ä–∞–º–µ—Ç—Ä days=5 –æ–∑–Ω–∞—á–∞–µ—Ç: –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª—ã, –∑–∞—Ç–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –¥–Ω–µ–π
        """
        cache_path = Path(self.cache_dir) / file_path.replace("/", "_")
        
        # –ï—Å–ª–∏ prefer_cache=True, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫
        # –∏ –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –æ–±–ª–∞–∫–∞, –µ—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å –≤ –∫—ç—à–µ
        if self.prefer_cache and cache_path.exists():
            try:
                file_size = cache_path.stat().st_size
                if file_size >= 8:
                    with open(cache_path, "rb") as f:
                        first_4_bytes = f.read(4)
                    if first_4_bytes == b"PAR1":
                        # –§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–∑ –∫—ç—à–∞ –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –æ–±–ª–∞–∫—É
                        df = pl.read_parquet(cache_path)
                        return df
            except Exception as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∏–∑ –∫—ç—à–∞ {file_path}: {e}, –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –æ–±–ª–∞–∫–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        if use_cache and cache_path.exists():
            try:
                file_size = cache_path.stat().st_size
                # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –±–∞–π—Ç—ã –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                if file_size >= 8:
                    with open(cache_path, "rb") as f:
                        first_4_bytes = f.read(4)
                        f.seek(-4, 2)
                        last_4_bytes = f.read(4)
                    
                    if first_4_bytes == b"PAR1" and last_4_bytes == b"PAR1":
                        # –§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, —á–∏—Ç–∞–µ–º
                        try:
                            df = pl.read_parquet(cache_path)
                            return df
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ parquet {file_path} (–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ PAR1): {e}")
                            # –§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω, —É–¥–∞–ª—è–µ–º
                            cache_path.unlink()
                    else:
                        # –§–∞–π–ª –ø–æ–≤—Ä–µ–∂–¥–µ–Ω (–Ω–µ–ø–æ–ª–Ω—ã–π), —É–¥–∞–ª—è–µ–º –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º
                        print(f"‚ö† –§–∞–π–ª {file_path} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω (–Ω–µ—Ç PAR1 –≤ –Ω–∞—á–∞–ª–µ –∏–ª–∏ –∫–æ–Ω—Ü–µ), —É–¥–∞–ª—è–µ–º...")
                        cache_path.unlink()
                else:
                    # –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π
                    cache_path.unlink()
            except Exception as e:
                # –ï—Å–ª–∏ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –∫—ç—à–∞, —É–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                try:
                    cache_path.unlink()
                except:
                    pass
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
        
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        
        print(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ {file_path} –∏–∑ {download_url}...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Å—Å–∏—é –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è
        import time
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': f'https://disk.yandex.ru/d/{self.folder_id}'
        })
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –∑–∞–¥–µ—Ä–∂–∫—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–∞–ø—á–∏
            time.sleep(0.5)
            
            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ (users.pq –º–æ–∂–µ—Ç –±—ã—Ç—å ~100MB)
            response = session.get(download_url, stream=True, timeout=300, allow_redirects=True)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (–∫–∞–ø—á–∞ –∏–ª–∏ –æ—à–∏–±–∫–∞)
            content_type = response.headers.get('content-type', '').lower()
            if 'text/html' in content_type or 'application/xhtml' in content_type:
                # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                first_chunk = next(response.iter_content(chunk_size=1024), b'')
                first_chunk_lower = first_chunk.lower()
                if b'<html' in first_chunk_lower or b'captcha' in first_chunk_lower or b'forbidden' in first_chunk_lower or b'<!doctype' in first_chunk_lower:
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL
                    print(f"‚ö† –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –≤–µ—Ä–Ω—É–ª HTML. –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL –¥–ª—è {file_path}...")
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É
                    # –î–ª—è —Ñ–∞–π–ª–æ–≤ –≤ –ø–æ–¥–ø–∞–ø–∫–∞—Ö —ç—Ç–æ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ API —Ç–æ–∫–µ–Ω–∞
                    raise ValueError(f"–Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ –≤–µ—Ä–Ω—É–ª HTML –≤–º–µ—Å—Ç–æ —Ñ–∞–π–ª–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, —Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–∞–ø—á–∞ –∏–ª–∏ —Ñ–∞–π–ª –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω). Content-Type: {content_type}. –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫ API —Å —Ç–æ–∫–µ–Ω–æ–º.")
            
            response.raise_for_status()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ URL
            total_size = int(response.headers.get('content-length', 0))
            if total_size == 0:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä –∏–∑ URL –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)
                import re
                size_match = re.search(r'fsize=(\d+)', download_url)
                if size_match:
                    total_size = int(size_match.group(1))
                    print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∏–∑ URL: {total_size} –±–∞–π—Ç ({total_size / 1024 / 1024:.2f} MB)")
                else:
                    print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {file_path} –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω")
            
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                try:
                    downloaded_size = 0
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    chunk_size = 65536 if total_size > 10 * 1024 * 1024 else 8192  # 64KB –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                    
                    with open(cache_path, "wb") as f:
                        for chunk in response.iter_content(chunk_size=chunk_size):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤
                                if total_size > 0 and downloaded_size % (10 * 1024 * 1024) == 0:
                                    progress = (downloaded_size / total_size) * 100
                                    print(f"  –ü—Ä–æ–≥—Ä–µ—Å—Å: {downloaded_size / 1024 / 1024:.1f} MB / {total_size / 1024 / 1024:.1f} MB ({progress:.1f}%)")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    file_size = cache_path.stat().st_size
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–∫–∞—á–∞–Ω –ø–æ–ª–Ω–æ—Å—Ç—å—é
                    if total_size > 0:
                        if file_size < total_size:
                            print(f"‚ö† –§–∞–π–ª —Å–∫–∞—á–∞–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é: {file_size}/{total_size} –±–∞–π—Ç ({file_size / total_size * 100:.1f}%). –ü–æ–ø—ã—Ç–∫–∞ {retry_count + 1}/{max_retries}")
                            if retry_count < max_retries - 1:
                                # –£–¥–∞–ª—è–µ–º –Ω–µ–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                                cache_path.unlink()
                                retry_count += 1
                                time.sleep(3)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                                # –ü–µ—Ä–µ–æ—Ç–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º —Ç–∞–π–º–∞—É—Ç–æ–º
                                response = session.get(download_url, stream=True, timeout=300, allow_redirects=True)
                                response.raise_for_status()
                                continue
                            else:
                                raise ValueError(f"–§–∞–π–ª —Å–∫–∞—á–∞–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {file_size}/{total_size} –±–∞–π—Ç")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    if file_size < 4:
                        raise ValueError(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π: {file_size} –±–∞–π—Ç")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ HTML —Ñ–∞–π–ª
                    with open(cache_path, "rb") as f:
                        first_bytes = f.read(min(1024, file_size))
                        if b'<html' in first_bytes.lower() or b'<!doctype' in first_bytes.lower():
                            raise ValueError(f"–°–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è HTML —Å—Ç—Ä–∞–Ω–∏—Ü–µ–π, –∞ –Ω–µ Parquet —Ñ–∞–π–ª–æ–º")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É Parquet (–¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è –ò –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è –Ω–∞ PAR1)
                    with open(cache_path, "rb") as f:
                        first_4_bytes = f.read(4)
                        if file_size >= 8:
                            f.seek(-4, 2)  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∫–æ–Ω—Ü—É —Ñ–∞–π–ª–∞
                            last_4_bytes = f.read(4)
                        else:
                            last_4_bytes = b""
                    
                    # Parquet —Ñ–∞–π–ª –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è –ò –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è –Ω–∞ PAR1
                    if first_4_bytes != b"PAR1":
                        raise ValueError(f"–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º Parquet —Ñ–∞–π–ª–æ–º (–Ω–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å PAR1). –ü–µ—Ä–≤—ã–µ –±–∞–π—Ç—ã: {first_4_bytes.hex()}")
                    
                    if file_size >= 8 and last_4_bytes != b"PAR1":
                        raise ValueError(f"–§–∞–π–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º Parquet —Ñ–∞–π–ª–æ–º (–Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ PAR1). –ü–æ—Å–ª–µ–¥–Ω–∏–µ –±–∞–π—Ç—ã: {last_4_bytes.hex()}, —Ä–∞–∑–º–µ—Ä: {file_size} –±–∞–π—Ç. –í–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª —Å–∫–∞—á–∞–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é.")
                    
                    print(f"‚úÖ –§–∞–π–ª {file_path} —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω ({file_size} –±–∞–π—Ç, {file_size / 1024 / 1024:.2f} MB, –ø—Ä–æ–≤–µ—Ä–∫–∞ PAR1 –ø—Ä–æ–π–¥–µ–Ω–∞)")
                    
                    # –ß–∏—Ç–∞–µ–º –∏–∑ –∫—ç—à–∞
                    return pl.read_parquet(cache_path)
                    
                except Exception as e:
                    if retry_count < max_retries - 1:
                        print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏, –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ {retry_count + 1}/{max_retries}: {e}")
                        if cache_path.exists():
                            cache_path.unlink()
                        retry_count += 1
                        time.sleep(3)
                        # –ü–µ—Ä–µ–æ—Ç–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
                        response = session.get(download_url, stream=True, timeout=300, allow_redirects=True)
                        response.raise_for_status()
                        continue
                    else:
                        raise
            
        except requests.exceptions.RequestException as e:
            error_msg = str(e)
            if '403' in error_msg or 'captcha' in error_msg.lower():
                print(f"–û—à–∏–±–∫–∞ 403 (–∫–∞–ø—á–∞) –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {file_path}. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ API —Ç–æ–∫–µ–Ω.")
            else:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {file_path}: {e}")
            if cache_path.exists():
                cache_path.unlink()  # –£–¥–∞–ª—è–µ–º –Ω–µ–ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª
            raise
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            if cache_path.exists():
                cache_path.unlink()  # –£–¥–∞–ª—è–µ–º –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            raise
    
    def load_marketplace_events(
        self,
        file_list: Optional[List[str]] = None,
        limit: Optional[int] = None,
        days: Optional[int] = None
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞.
        
        –í–ê–ñ–ù–û: –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –±–µ–∑ API —Ç–æ–∫–µ–Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å
        –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä file_list.
        
        :param file_list: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
                         –ù–∞–ø—Ä–∏–º–µ—Ä: ["01082.pq", "01081.pq", "01080.pq"]
                         –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω –∏ –Ω–µ—Ç API —Ç–æ–∫–µ–Ω–∞, –±—É–¥–µ—Ç –æ—à–∏–±–∫–∞
        :param limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤ (–µ—Å–ª–∏ file_list –Ω–µ —É–∫–∞–∑–∞–Ω)
        :param days: –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ –¥–∞–Ω–Ω—ã–µ)
        :return: LazyFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        """
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if file_list:
            events_files = [{"name": f, "type": "file"} for f in file_list]
        else:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω)
            if not self.api_token:
                raise ValueError(
                    "–î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –±–µ–∑ API —Ç–æ–∫–µ–Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å file_list "
                    "—Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä:\n"
                    "loader.load_marketplace_events(file_list=['01082.pq', '01081.pq'])"
                )
            
            events_files = self.list_files("marketplace/events")
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
            if limit:
                events_files = events_files[:limit]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –∫—ç—à–∞
        import time
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        frames = []
        cache_path = Path(self.cache_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —É–∂–µ –≤ –∫—ç—à–µ
        cached_files = {}
        for file_info in events_files:
            file_path = f"marketplace/events/{file_info['name']}"
            cache_file_path = cache_path / file_path.replace("/", "_")
            if cache_file_path.exists():
                cached_files[file_info['name']] = cache_file_path
        
        # –ï—Å–ª–∏ –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        if len(cached_files) == len(events_files) and len(events_files) > 1:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞
            def load_cached_file(file_info):
                file_path = f"marketplace/events/{file_info['name']}"
                try:
                    df = self.read_parquet_from_url(file_path, normalize=True, use_cache=True)
                    if df.height > 0 and "user_id" in df.columns:
                        return (file_info['name'], df)
                except Exception as e:
                    print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_info['name']} –∏–∑ –∫—ç—à–∞: {e}")
                return None
            
            # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
            max_workers = min(8, len(events_files), os.cpu_count() or 4)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {executor.submit(load_cached_file, file_info): file_info for file_info in events_files}
                for future in as_completed(futures):
                    result = future.result()
                    if result:
                        frames.append(result[1])
                        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –∏–∑ –∫—ç—à–∞ {result[0]}: {frames[-1].height} —Å—Ç—Ä–æ–∫")
        else:
            # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã –Ω–µ –≤ –∫—ç—à–µ)
            for idx, file_info in enumerate(events_files):
                file_path = f"marketplace/events/{file_info['name']}"
                try:
                    # –ó–∞–¥–µ—Ä–∂–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤ –Ω–µ –∏–∑ –∫—ç—à–∞
                    if file_info['name'] not in cached_files and idx > 0:
                        time.sleep(0.5)
                    
                    df = self.read_parquet_from_url(file_path, normalize=True)
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ
                    if df.height > 0:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ user_id
                        if "user_id" in df.columns:
                            frames.append(df)
                            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω {file_info['name']}: {df.height} —Å—Ç—Ä–æ–∫")
                        else:
                            print(f"‚ö† –§–∞–π–ª {file_info['name']} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É 'user_id'")
                    else:
                        print(f"‚ö† –§–∞–π–ª {file_info['name']} –ø—É—Å—Ç–æ–π")
                        
                    # –ï—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
                    if len(frames) >= 1 and limit and limit <= 1:
                        break
                        
                except Exception as e:
                    error_str = str(e)
                    if '403' in error_str or 'captcha' in error_str.lower() or 'forbidden' in error_str.lower():
                        print(f"‚ö† –û—à–∏–±–∫–∞ 403 –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_info['name']}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        time.sleep(2.0)
                    elif 'HTML' in error_str or 'html' in error_str:
                        print(f"‚ö† HTML –≤–º–µ—Å—Ç–æ —Ñ–∞–π–ª–∞ {file_info['name']}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        time.sleep(1.0)
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_info['name']}: {e}")
                    continue
        
        if not frames:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π LazyFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ö–µ–º–æ–π –≤–º–µ—Å—Ç–æ –æ—à–∏–±–∫–∏
            print("‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame.")
            return pl.DataFrame({
                "user_id": pl.Utf8,
                "item_id": pl.Utf8,
                "category_id": pl.Utf8,
                "timestamp": pl.Datetime,
                "domain": pl.Utf8
            }).lazy()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ LazyFrame
        combined = pl.concat(frames).lazy()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
        if days and days > 0:
            from datetime import datetime, timedelta
            cutoff_date = datetime.now() - timedelta(days=days)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ timestamp
            schema = combined.collect_schema()
            if "timestamp" in schema:
                timestamp_dtype = schema["timestamp"]
                
                # Duration –Ω–µ–ª—å–∑—è —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å Datetime –Ω–∞–ø—Ä—è–º—É—é - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                if timestamp_dtype == pl.Duration:
                    print(f"‚ö† Timestamp –≤ —Ñ–æ—Ä–º–∞—Ç–µ Duration, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ (Duration –Ω–µ–ª—å–∑—è —Å—Ä–∞–≤–Ω–∏—Ç—å —Å Datetime)")
                    return combined
                
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ Datetime —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ Duration
                if timestamp_dtype != pl.Datetime:
                    try:
                        # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                        combined = combined.with_columns(
                            pl.col("timestamp").cast(pl.Datetime, strict=False)
                        )
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ
                        new_schema = combined.collect_schema()
                        if new_schema.get("timestamp") != pl.Datetime:
                            print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å timestamp –≤ Datetime (—Ç–∏–ø: {timestamp_dtype}), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
                            return combined
                    except Exception as e:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                        print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å timestamp –≤ Datetime: {e}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ")
                        return combined
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pl.lit –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                try:
                    combined = combined.filter(pl.col("timestamp") >= pl.lit(cutoff_date))
                    print(f"üìÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è marketplace: –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π (—Å {cutoff_date.date()})")
                except Exception as e:
                    print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ: {e}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
                    return combined
        
        return combined
    
    def load_payments_events(
        self,
        file_list: Optional[List[str]] = None,
        limit: Optional[int] = None,
        days: Optional[int] = None,
        user_id: Optional[str] = None
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –ø–ª–∞—Ç–µ–∂–µ–π.
        
        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω user_id –∏ —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç predicate pushdown
        –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –î–û –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–º—è—Ç—å.
        
        :param file_list: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        :param limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
        :param days: –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
        :return: LazyFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        """
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if file_list:
            events_files = [{"name": f, "type": "file"} for f in file_list]
        else:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω)
            if not self.api_token:
                # –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –ø–∞–ø–æ–∫ –±–µ–∑ API –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
                return pl.DataFrame().lazy()
            
            events_files = self.list_files("payments/events")
            
            if limit:
                events_files = events_files[:limit]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –∫—ç—à–∞
        import time
        from src.data.data_parser import normalize_dataframe
        frames = []
        lazy_frames = []
        cache_path = Path(self.cache_dir)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —É–∂–µ –≤ –∫—ç—à–µ
        cached_files = {}
        for file_info in events_files:
            file_path = f"payments/events/{file_info['name']}"
            cache_file_path = cache_path / file_path.replace("/", "_")
            if cache_file_path.exists():
                cached_files[file_info['name']] = cache_file_path
        
        # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω user_id –∏ –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º LazyFrame —Å predicate pushdown
        use_lazy_optimization = user_id and len(cached_files) == len(events_files) and len(events_files) > 0
        
        if use_lazy_optimization:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º LazyFrame –¥–ª—è predicate pushdown - —Ñ–∏–ª—å—Ç—Ä—É–µ–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏
            print(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º predicate pushdown –¥–ª—è user_id={user_id} (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –î–û –∑–∞–≥—Ä—É–∑–∫–∏)")
            for file_info in events_files:
                file_path = f"payments/events/{file_info['name']}"
                cache_file_path = cached_files.get(file_info['name'])
                if cache_file_path and cache_file_path.exists():
                    try:
                        # –ß–∏—Ç–∞–µ–º –∫–∞–∫ LazyFrame –¥–ª—è predicate pushdown
                        lazy_df = pl.scan_parquet(str(cache_file_path))
                        
                        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ LazyFrame (–±–∞–∑–æ–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
                        schema = lazy_df.collect_schema()
                        
                        # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                        rename_dict = {}
                        if "price" in schema and "amount" not in schema:
                            rename_dict["price"] = "amount"
                        if "user_id" not in schema:
                            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ user_id
                            continue
                        
                        if rename_dict:
                            lazy_df = lazy_df.rename(rename_dict)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º domain –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
                        if "domain" not in lazy_df.collect_schema():
                            lazy_df = lazy_df.with_columns(pl.lit("payments").alias("domain"))
                        
                        # –ü–†–ò–ú–ï–ù–Ø–ï–ú –§–ò–õ–¨–¢–† –î–û collect() - —ç—Ç–æ –∏ –µ—Å—Ç—å predicate pushdown!
                        # Polars –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —ç—Ç–æ –∏ —á–∏—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ Parquet
                        lazy_df = lazy_df.filter(pl.col("user_id").cast(pl.Utf8) == str(user_id))
                        
                        lazy_frames.append(lazy_df)
                        print(f"   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω LazyFrame –¥–ª—è {file_info['name']} —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ user_id (predicate pushdown)")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LazyFrame –¥–ª—è {file_info['name']}: {e}")
                        # Fallback: –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∫ –æ–±—ã—á–Ω–æ
                        try:
                            df = self.read_parquet_from_url(file_path, normalize=True, use_cache=True)
                            if df.height > 0 and "user_id" in df.columns:
                                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
                                df = df.filter(pl.col("user_id").cast(pl.Utf8) == str(user_id))
                                if df.height > 0:
                                    frames.append(df)
                        except Exception as e2:
                            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ fallback –∑–∞–≥—Ä—É–∑–∫–µ {file_info['name']}: {e2}")
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º LazyFrames
            if lazy_frames:
                combined = pl.concat(lazy_frames)
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –Ω–∞ —É—Ä–æ–≤–Ω–µ LazyFrame
                # (–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ collect())
                if days and days > 0:
                    from datetime import datetime, timedelta
                    cutoff_date = datetime.now() - timedelta(days=days)
                    schema = combined.collect_schema()
                    if "timestamp" in schema and schema["timestamp"] == pl.Datetime:
                        combined = combined.filter(pl.col("timestamp") >= pl.lit(cutoff_date))
                        print(f"üìÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è payments: –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π (—Å {cutoff_date.date()})")
                return combined
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–µ—Å–ª–∏ –Ω–µ—Ç user_id –∏–ª–∏ —Ñ–∞–π–ª—ã –Ω–µ –≤—Å–µ –≤ –∫—ç—à–µ)
            # –ï—Å–ª–∏ –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            if len(cached_files) == len(events_files) and len(events_files) > 1:
                # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –∫—ç—à–∞
                def load_cached_file(file_info):
                    file_path = f"payments/events/{file_info['name']}"
                    try:
                        df = self.read_parquet_from_url(file_path, normalize=True, use_cache=True)
                        if df.height > 0 and "user_id" in df.columns:
                            return (file_info['name'], df)
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_info['name']} –∏–∑ –∫—ç—à–∞: {e}")
                    return None
                
                # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
                max_workers = min(8, len(events_files), os.cpu_count() or 4)
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    futures = {executor.submit(load_cached_file, file_info): file_info for file_info in events_files}
                    for future in as_completed(futures):
                        result = future.result()
                        if result:
                            frames.append(result[1])
            else:
                # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª—ã –Ω–µ –≤ –∫—ç—à–µ)
                for idx, file_info in enumerate(events_files):
                    file_path = f"payments/events/{file_info['name']}"
                    try:
                        # –ó–∞–¥–µ—Ä–∂–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ñ–∞–π–ª–æ–≤ –Ω–µ –∏–∑ –∫—ç—à–∞
                        if file_info['name'] not in cached_files and idx > 0:
                            time.sleep(0.5)
                        
                        df = self.read_parquet_from_url(file_path, normalize=True)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ DataFrame –Ω–µ –ø—É—Å—Ç–æ–π
                        if df.height > 0:
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ user_id
                            if "user_id" in df.columns:
                                # –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ amount/price
                                if "amount" in df.columns:
                                    amount_sample = df.select(pl.col("amount")).head(3).to_series().to_list()
                                    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {df.height} —Å—Ç—Ä–æ–∫, amount: {amount_sample}")
                                elif "price" in df.columns:
                                    print(f"   ‚ö† –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç 'price' –≤–º–µ—Å—Ç–æ 'amount'. –ö–æ–ª–æ–Ω–∫–∏: {df.columns}")
                                frames.append(df)
                            else:
                                print(f"   ‚ö† –§–∞–π–ª {file_path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É 'user_id'. –ö–æ–ª–æ–Ω–∫–∏: {df.columns}")
                        else:
                            print(f"   ‚ö† –§–∞–π–ª {file_path} –ø—É—Å—Ç–æ–π")
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
                        continue
        
        if not frames and not lazy_frames:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π LazyFrame —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ö–µ–º–æ–π
            return pl.DataFrame({
                "user_id": pl.Utf8,
                "brand_id": pl.Utf8,
                "amount": pl.Float64,
                "timestamp": pl.Datetime,
                "domain": pl.Utf8
            }).lazy()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ LazyFrame
        if frames:
            combined = pl.concat(frames).lazy()
        else:
            combined = pl.concat(lazy_frames)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π
        if days and days > 0:
            from datetime import datetime, timedelta
            cutoff_date = datetime.now() - timedelta(days=days)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ timestamp
            schema = combined.collect_schema()
            if "timestamp" in schema:
                timestamp_dtype = schema["timestamp"]
                
                # Duration –Ω–µ–ª—å–∑—è —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å Datetime –Ω–∞–ø—Ä—è–º—É—é - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                if timestamp_dtype == pl.Duration:
                    print(f"‚ö† Timestamp –≤ —Ñ–æ—Ä–º–∞—Ç–µ Duration, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ (Duration –Ω–µ–ª—å–∑—è —Å—Ä–∞–≤–Ω–∏—Ç—å —Å Datetime)")
                    return combined
                
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ Datetime —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ Duration
                if timestamp_dtype != pl.Datetime:
                    try:
                        # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                        combined = combined.with_columns(
                            pl.col("timestamp").cast(pl.Datetime, strict=False)
                        )
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ
                        new_schema = combined.collect_schema()
                        if new_schema.get("timestamp") != pl.Datetime:
                            print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å timestamp –≤ Datetime (—Ç–∏–ø: {timestamp_dtype}), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
                            return combined
                    except Exception as e:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é
                        print(f"‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å timestamp –≤ Datetime: {e}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ –¥–∞—Ç–µ")
                        return combined
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º pl.lit –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                try:
                    combined = combined.filter(pl.col("timestamp") >= pl.lit(cutoff_date))
                    print(f"üìÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è payments: –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days} –¥–Ω–µ–π (—Å {cutoff_date.date()})")
                except Exception as e:
                    print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –¥–∞—Ç–µ: {e}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é")
                    return combined
        
        return combined
    
    def load_brands(self) -> pl.DataFrame:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –±—Ä–µ–Ω–¥–æ–≤."""
        return self.read_parquet_from_url("brands.pq")
    
    def load_marketplace_items(
        self,
        brand_ids: Optional[List[str]] = None,
        item_ids: Optional[List[str]] = None,
        use_lazy: bool = True,
        include_embedding: bool = False
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
        
        :param brand_ids: –°–ø–∏—Å–æ–∫ brand_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param item_ids: –°–ø–∏—Å–æ–∫ item_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param use_lazy: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LazyFrame –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        :param include_embedding: –ó–∞–≥—Ä—É–∂–∞—Ç—å –ª–∏ embedding (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω, —Ç.–∫. –∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞)
        :return: LazyFrame –∏–ª–∏ DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º projection pushdown - –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            # –í–ê–ñ–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Yandex Cloud Data Set
            # –°–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Yandex Cloud Data Set:
            # - item_id: str (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
            # - brand_id: u64 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # - category: str (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - category_id: ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # - subcategory: str (–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - price: f64 (—Ü–µ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            needed_cols = ["item_id"]  # item_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            optional_cols = ["brand_id", "category", "category_id", "subcategory", "price"]  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if include_embedding:
                optional_cols.append("embedding")  # –î–æ–±–∞–≤–ª—è–µ–º embedding —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ LazyFrame –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            cache_path = Path(self.cache_dir)
            cache_file = cache_path / "marketplace_items.pq"
            
            if cache_file.exists():
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫—ç—à–∞ —Å projection pushdown
                lazy_df = pl.scan_parquet(str(cache_file))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                schema = lazy_df.collect_schema()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                if "item_id" not in schema:
                    print(f"‚ö† –í marketplace/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(schema.keys())}")
                    return pl.DataFrame().lazy()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                for col in optional_cols:
                    if col in schema:
                        available_cols.append(col)
                
                # Projection pushdown: –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                lazy_df = lazy_df.select(available_cols)
                
                # Predicate pushdown: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –î–û –∑–∞–≥—Ä—É–∑–∫–∏
                # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ available_cols (–ø–æ—Å–ª–µ select)
                if brand_ids and "brand_id" in available_cols:
                    try:
                        brand_ids_str = [str(bid) for bid in brand_ids]
                        lazy_df = lazy_df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                elif brand_ids:
                    print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ marketplace/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                
                if item_ids and "item_id" in available_cols:
                    try:
                        item_ids_str = [str(iid) for iid in item_ids]
                        lazy_df = lazy_df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                elif item_ids:
                    print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ marketplace/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                if use_lazy:
                    return lazy_df
                else:
                    return lazy_df.collect()
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –æ–±–ª–∞–∫–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ)
                print(f"‚ö† marketplace/items.pq –Ω–µ –≤ –∫—ç—à–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.")
                df = self.read_parquet_from_url("marketplace/items.pq", normalize=False)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                if "item_id" not in df.columns:
                    print(f"‚ö† –í marketplace/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
                    return pl.DataFrame().lazy() if use_lazy else pl.DataFrame()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                optional_cols = ["brand_id", "category", "category_id", "subcategory", "price"]
                if include_embedding:
                    optional_cols.append("embedding")
                for col in optional_cols:
                    if col in df.columns:
                        available_cols.append(col)
                
                if available_cols:
                    df = df.select(available_cols)
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
                    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ df.columns (–ø–æ—Å–ª–µ select)
                    if brand_ids and "brand_id" in df.columns:
                        try:
                            brand_ids_str = [str(bid) for bid in brand_ids]
                            df = df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    elif brand_ids:
                        print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ marketplace/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    
                    if item_ids and "item_id" in df.columns:
                        try:
                            item_ids_str = [str(iid) for iid in item_ids]
                            df = df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                    elif item_ids:
                        print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ marketplace/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                return df.lazy() if use_lazy else df
                
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ marketplace/items.pq: {e}")
            return pl.DataFrame().lazy()
    
    def load_retail_items(
        self,
        brand_ids: Optional[List[str]] = None,
        item_ids: Optional[List[str]] = None,
        use_lazy: bool = True,
        include_embedding: bool = False
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Ä–∏—Ç–µ–π–ª–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
        
        :param brand_ids: –°–ø–∏—Å–æ–∫ brand_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param item_ids: –°–ø–∏—Å–æ–∫ item_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param use_lazy: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LazyFrame –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        :param include_embedding: –ó–∞–≥—Ä—É–∂–∞—Ç—å –ª–∏ embedding (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω, —Ç.–∫. –∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞)
        :return: LazyFrame –∏–ª–∏ DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º projection pushdown - –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            # –°–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Yandex Cloud Data Set –¥–ª—è retail/items.pq:
            # - item_id: str (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
            # - brand_id: u64 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # - category: str (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - subcategory: str (–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - price: f64 (—Ü–µ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º)
            # - embedding: array[f32, 300] (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –í retail/items.pq –ù–ï–¢ category_id (—Ç–æ–ª—å–∫–æ –≤ marketplace/items.pq)
            needed_cols = ["item_id"]  # item_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            optional_cols = ["brand_id", "category", "subcategory", "price"]  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            if include_embedding:
                optional_cols.append("embedding")  # –î–æ–±–∞–≤–ª—è–µ–º embedding —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ LazyFrame –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            cache_path = Path(self.cache_dir)
            cache_file = cache_path / "retail_items.pq"
            
            if cache_file.exists():
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫—ç—à–∞ —Å projection pushdown
                lazy_df = pl.scan_parquet(str(cache_file))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                schema = lazy_df.collect_schema()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                for col in optional_cols:
                    if col in schema:
                        available_cols.append(col)
                
                if "item_id" not in schema:
                    print(f"‚ö† –í retail/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(schema.keys())}")
                    return pl.DataFrame().lazy()
                
                # Projection pushdown: –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                lazy_df = lazy_df.select(available_cols)
                
                # Predicate pushdown: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –î–û –∑–∞–≥—Ä—É–∑–∫–∏
                # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ available_cols (–ø–æ—Å–ª–µ select)
                if brand_ids and "brand_id" in available_cols:
                    try:
                        brand_ids_str = [str(bid) for bid in brand_ids]
                        lazy_df = lazy_df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                elif brand_ids:
                    print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ retail/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                
                if item_ids and "item_id" in available_cols:
                    try:
                        item_ids_str = [str(iid) for iid in item_ids]
                        lazy_df = lazy_df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                elif item_ids:
                    print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ retail/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                if use_lazy:
                    return lazy_df
                else:
                    return lazy_df.collect()
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –æ–±–ª–∞–∫–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ)
                print(f"‚ö† retail/items.pq –Ω–µ –≤ –∫—ç—à–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.")
                df = self.read_parquet_from_url("retail/items.pq", normalize=False)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                if "item_id" not in df.columns:
                    print(f"‚ö† –í retail/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
                    return pl.DataFrame().lazy() if use_lazy else pl.DataFrame()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                # –°–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Yandex Cloud Data Set –¥–ª—è retail/items.pq:
                # - category: str (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞)
                # - subcategory: str (–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è –∫–∞–∫ —Å—Ç—Ä–æ–∫–∞)
                # - price: f64 (—Ü–µ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π, –º–æ–∂–µ—Ç –±—ã—Ç—å null –∏–ª–∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º)
                # –ü–†–ò–ú–ï–ß–ê–ù–ò–ï: –í retail/items.pq –ù–ï–¢ category_id (—Ç–æ–ª—å–∫–æ –≤ marketplace/items.pq)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                optional_cols = ["brand_id", "category", "subcategory", "price"]
                if include_embedding:
                    optional_cols.append("embedding")
                for col in optional_cols:
                    if col in df.columns:
                        available_cols.append(col)
                
                if available_cols:
                    df = df.select(available_cols)
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
                    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ df.columns (–ø–æ—Å–ª–µ select)
                    if brand_ids and "brand_id" in df.columns:
                        try:
                            brand_ids_str = [str(bid) for bid in brand_ids]
                            df = df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    elif brand_ids:
                        print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ retail/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    
                    if item_ids and "item_id" in df.columns:
                        try:
                            item_ids_str = [str(iid) for iid in item_ids]
                            df = df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                    elif item_ids:
                        print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ retail/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                return df.lazy() if use_lazy else df
                
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ retail/items.pq: {e}")
            return pl.DataFrame().lazy()
    
    def load_payments_items(
        self,
        brand_ids: Optional[List[str]] = None,
        item_ids: Optional[List[str]] = None,
        use_lazy: bool = True,
        include_embedding: bool = False
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤ payments —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π.
        
        :param brand_ids: –°–ø–∏—Å–æ–∫ brand_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param item_ids: –°–ø–∏—Å–æ–∫ item_id –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown) - —ç–∫–æ–Ω–æ–º–∏—Ç –ø–∞–º—è—Ç—å
        :param use_lazy: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LazyFrame –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        :param include_embedding: –ó–∞–≥—Ä—É–∂–∞—Ç—å –ª–∏ embedding (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω, —Ç.–∫. –∑–∞–Ω–∏–º–∞–µ—Ç –º–Ω–æ–≥–æ –º–µ—Å—Ç–∞)
        :return: LazyFrame –∏–ª–∏ DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º projection pushdown - –∑–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            # –°–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ Yandex Cloud Data Set –¥–ª—è payments/items.pq:
            # - item_id: str (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) - –º–æ–∂–µ—Ç –±—ã—Ç—å approximate_item_id
            # - brand_id: u64 (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # - category: str (–Ω–∞–∑–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - category_id: ID –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            # - subcategory: str (–ø–æ–¥–∫–∞—Ç–µ–≥–æ—Ä–∏—è, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            # - price: f64 (—Ü–µ–Ω–∞ –∫–∞–∫ —á–∏—Å–ª–æ —Å –ø–ª–∞–≤–∞—é—â–µ–π —Ç–æ—á–∫–æ–π, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å null)
            needed_cols = ["item_id"]  # item_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω
            optional_cols = ["brand_id", "category", "category_id", "subcategory", "price"]  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            if include_embedding:
                optional_cols.append("embedding")  # –î–æ–±–∞–≤–ª—è–µ–º embedding —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
            
            # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–∫ LazyFrame –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            cache_path = Path(self.cache_dir)
            cache_file = cache_path / "payments_items.pq"
            
            if cache_file.exists():
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫—ç—à–∞ —Å projection pushdown
                lazy_df = pl.scan_parquet(str(cache_file))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∫–∞–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                schema = lazy_df.collect_schema()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                for col in optional_cols:
                    if col in schema:
                        available_cols.append(col)
                
                if "item_id" not in schema:
                    print(f"‚ö† –í payments/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(schema.keys())}")
                    return pl.DataFrame().lazy()
                
                # Projection pushdown: –≤—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                lazy_df = lazy_df.select(available_cols)
                
                # Predicate pushdown: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –î–û –∑–∞–≥—Ä—É–∑–∫–∏
                # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ available_cols (–ø–æ—Å–ª–µ select)
                if brand_ids and "brand_id" in available_cols:
                    try:
                        brand_ids_str = [str(bid) for bid in brand_ids]
                        lazy_df = lazy_df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                elif brand_ids:
                    print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ payments/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                
                if item_ids and "item_id" in available_cols:
                    try:
                        item_ids_str = [str(iid) for iid in item_ids]
                        lazy_df = lazy_df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                        print(f"‚ö° –ü—Ä–∏–º–µ–Ω–µ–Ω predicate pushdown: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º –î–û –∑–∞–≥—Ä—É–∑–∫–∏")
                    except Exception as e:
                        print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                elif item_ids:
                    print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ payments/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {available_cols}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                if use_lazy:
                    return lazy_df
                else:
                    return lazy_df.collect()
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –æ–±–ª–∞–∫–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫—ç—à–µ)
                print(f"‚ö† payments/items.pq –Ω–µ –≤ –∫—ç—à–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.")
                df = self.read_parquet_from_url("payments/items.pq", normalize=False)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
                if "item_id" not in df.columns:
                    print(f"‚ö† –í payments/items.pq –Ω–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ item_id")
                    print(f"   –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
                    return pl.DataFrame().lazy() if use_lazy else pl.DataFrame()
                
                # –°–æ–±–∏—Ä–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ + –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ)
                available_cols = ["item_id"]  # item_id –≤—Å–µ–≥–¥–∞ –µ—Å—Ç—å
                optional_cols = ["brand_id", "category", "category_id", "subcategory", "price"]
                if include_embedding:
                    optional_cols.append("embedding")
                for col in optional_cols:
                    if col in df.columns:
                        available_cols.append(col)
                
                if available_cols:
                    df = df.select(available_cols)
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ brand_id –∏ item_id –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã
                    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ df.columns (–ø–æ—Å–ª–µ select)
                    if brand_ids and "brand_id" in df.columns:
                        try:
                            brand_ids_str = [str(bid) for bid in brand_ids]
                            df = df.filter(pl.col("brand_id").cast(pl.Utf8).is_in(brand_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(brand_ids)} –±—Ä–µ–Ω–¥–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ brand_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    elif brand_ids:
                        print(f"‚ö† brand_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ payments/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ brand_id.")
                    
                    if item_ids and "item_id" in df.columns:
                        try:
                            item_ids_str = [str(iid) for iid in item_ids]
                            df = df.filter(pl.col("item_id").cast(pl.Utf8).is_in(item_ids_str))
                            print(f"‚ö° –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ {len(item_ids)} —Ç–æ–≤–∞—Ä–∞–º")
                        except Exception as e:
                            print(f"‚ö† –û—à–∏–±–∫–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ item_id: {e}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                    elif item_ids:
                        print(f"‚ö† item_id –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ payments/items.pq. –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {list(df.columns)}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ item_id.")
                
                return df.lazy() if use_lazy else df
                
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ payments/items.pq: {e}")
            return pl.DataFrame().lazy()
    
    def load_payments_receipts(
        self,
        file_list: Optional[List[str]] = None,
        limit: Optional[int] = None,
        days: Optional[int] = None,
        user_id: Optional[str] = None
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–µ–∫–∏ –∏–∑ payments/receipts —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ç–æ–≤–∞—Ä–æ–≤.
        
        :param file_list: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        :param limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
        :param days: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        :param user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (predicate pushdown)
        :return: LazyFrame —Å —á–µ–∫–∞–º–∏
        """
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if file_list:
            events_files = [{"name": f, "type": "file"} for f in file_list]
        else:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω)
            if not self.api_token:
                return pl.DataFrame().lazy()
            
            events_files = self.list_files("payments/receipts")
            
            if limit:
                events_files = events_files[:limit]
        
        # –ï—Å–ª–∏ –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –∫—ç—à–µ –ò –ø–µ—Ä–µ–¥–∞–Ω user_id, –∏—Å–ø–æ–ª—å–∑—É–µ–º predicate pushdown
        cache_path = Path(self.cache_dir)
        cached_files = [f for f in events_files if (cache_path / f"payments_receipts_{f['name']}").exists()]
        
        if user_id and len(cached_files) == len(events_files) and len(events_files) > 0:
            print(f"‚ö° –ò—Å–ø–æ–ª—å–∑—É–µ–º predicate pushdown –¥–ª—è receipts user_id={user_id}")
            lazy_frames = []
            for file_info in events_files:
                file_path = f"payments/receipts/{file_info['name']}"
                cache_file_path = cache_path / file_path.replace("/", "_")
                try:
                    lazy_df = pl.scan_parquet(str(cache_file_path))
                    schema = lazy_df.collect_schema()
                    if "user_id" in schema:
                        lazy_df = lazy_df.filter(pl.col("user_id").cast(pl.Utf8) == str(user_id))
                        lazy_frames.append(lazy_df)
                except Exception as e:
                    print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ LazyFrame –¥–ª—è receipts {file_info['name']}: {e}")
            
            if lazy_frames:
                combined = pl.concat(lazy_frames)
                if days and days > 0:
                    from datetime import datetime, timedelta
                    cutoff_date = datetime.now() - timedelta(days=days)
                    schema = combined.collect_schema()
                    if "timestamp" in schema and schema["timestamp"] == pl.Datetime:
                        combined = combined.filter(pl.col("timestamp") >= pl.lit(cutoff_date))
                return combined
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
        frames = []
        for file_info in events_files:
            file_path = f"payments/receipts/{file_info['name']}"
            try:
                df = self.read_parquet_from_url(file_path, normalize=False)
                if df.height > 0 and "user_id" in df.columns:
                    if user_id:
                        df = df.filter(pl.col("user_id").cast(pl.Utf8) == str(user_id))
                    if df.height > 0:
                        frames.append(df)
            except Exception as e:
                print(f"‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
                continue
        
        if not frames:
            return pl.DataFrame().lazy()
        
        combined = pl.concat(frames).lazy()
        
        if days and days > 0:
            from datetime import datetime, timedelta
            cutoff_date = datetime.now() - timedelta(days=days)
            schema = combined.collect_schema()
            if "timestamp" in schema:
                if schema["timestamp"] == pl.Datetime:
                    combined = combined.filter(pl.col("timestamp") >= pl.lit(cutoff_date))
        
        return combined
    
    def load_users(self) -> pl.DataFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
        
        –ü—Ä–æ–±—É–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ä–∞–∑–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π:
        - users.pq (–≤ –∫–æ—Ä–Ω–µ)
        - users/users.pq
        - data/users.pq
        """
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É users.pq
        possible_paths = [
            "users.pq",  # –í –∫–æ—Ä–Ω–µ –ø–∞–ø–∫–∏
            "users/users.pq",  # –í –ø–æ–¥–ø–∞–ø–∫–µ users
            "data/users.pq",  # –í –ø–æ–¥–ø–∞–ø–∫–µ data
            "users.pq",  # –ï—â–µ —Ä–∞–∑ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        ]
        
        for path in possible_paths:
            try:
                print(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å users.pq –∏–∑ –ø—É—Ç–∏: {path}")
                df = self.read_parquet_from_url(path, normalize=False)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ –ø—É—Å—Ç–æ–π
                if df.height > 0:
                    print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω users.pq –∏–∑ {path}, —Å—Ç—Ä–æ–∫: {df.height}")
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ user_id
                    if "user_id" in df.columns:
                        return df
                    else:
                        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
                        for alt_name in ["user", "userId", "userid", "uid", "client_id"]:
                            if alt_name in df.columns:
                                print(f"–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º {alt_name} –≤ user_id")
                                df = df.rename({alt_name: "user_id"})
                                return df
                        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: —Ñ–∞–π–ª {path} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–ª–æ–Ω–∫—É user_id. –ö–æ–ª–æ–Ω–∫–∏: {df.columns}")
                else:
                    print(f"–§–∞–π–ª {path} –ø—É—Å—Ç–æ–π")
            except Exception as e:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {path}: {e}")
                continue
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π DataFrame
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å users.pq –Ω–∏ –∏–∑ –æ–¥–Ω–æ–≥–æ –ø—É—Ç–∏")
        return pl.DataFrame()
    
    def load_retail_events(
        self,
        file_list: Optional[List[str]] = None,
        limit: Optional[int] = None
    ) -> pl.LazyFrame:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è —Ä–∏—Ç–µ–π–ª–∞.
        
        :param file_list: –°–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        :param limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
        :return: LazyFrame —Å–æ –≤—Å–µ–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        """
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if file_list:
            events_files = [{"name": f, "type": "file"} for f in file_list]
        else:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ —á–µ—Ä–µ–∑ API (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–æ–∫–µ–Ω)
            if not self.api_token:
                return pl.DataFrame().lazy()
            
            events_files = self.list_files("retail/events")
            
            if limit:
                events_files = events_files[:limit]
        
        frames = []
        for file_info in events_files:
            file_path = f"retail/events/{file_info['name']}"
            try:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                df = self.read_parquet_from_url(file_path, normalize=True)
                frames.append(df)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {file_path}: {e}")
                continue
        
        if not frames:
            return pl.DataFrame().lazy()
        
        return pl.concat(frames).lazy()


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)
_loader: Optional[YandexDiskLoader] = None


def init_loader(
    public_link: Optional[str] = None,
    api_token: Optional[str] = None,
    base_path: Optional[str] = None,
    prefer_cache: bool = False
) -> YandexDiskLoader:
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫.
    
    :param public_link: –ü—É–±–ª–∏—á–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –Ø–Ω–¥–µ–∫—Å –î–∏—Å–∫
    :param api_token: –¢–æ–∫–µ–Ω API (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    :param base_path: –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å dataset (–¥–ª—è API —Å —Ç–æ–∫–µ–Ω–æ–º)
                     –ü—Ä–∏–º–µ—Ä: "/–ó–∞–≥—Ä—É–∑–∫–∏/Dataset_case_1"
    :param prefer_cache: –ï—Å–ª–∏ True, —Å–∏—Å—Ç–µ–º–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫
                        –∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑ –æ–±–ª–∞–∫–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç –≤ –∫—ç—à–µ
    :return: –≠–∫–∑–µ–º–ø–ª—è—Ä –∑–∞–≥—Ä—É–∑—á–∏–∫–∞
    """
    global _loader
    _loader = YandexDiskLoader(
        public_link=public_link or os.getenv("YANDEX_DISK_PUBLIC_LINK"),
        api_token=api_token,
        base_path=base_path,
        prefer_cache=prefer_cache or os.getenv("PREFER_CACHE", "false").lower() == "true"
    )
    return _loader


def get_loader() -> Optional[YandexDiskLoader]:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫."""
    return _loader
